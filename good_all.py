import os
import json
import fitz  # PyMuPDF
import pandas as pd
import glob
from PIL import Image
import io
import pytesseract
import hashlib
from datetime import datetime
                    
# Tesseract ê²½ë¡œ ì„¤ì • (ì„¤ì¹˜ëœ ê²½ìš°)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

def extract_text_from_pdf(path):
    try:
        doc = fitz.open(path)
        full_text = ""
        
        for page_num, page in enumerate(doc, start=1):
            text = page.get_text()
            
            # í˜ì´ì§€ì— í…ìŠ¤íŠ¸ê°€ ì ìœ¼ë©´ OCR ìˆ˜í–‰ ì‹œë„
            if len(text.strip()) < 20:
                try:
                    pix = page.get_pixmap(dpi=300)
                    img = Image.open(io.BytesIO(pix.tobytes("png")))
                    ocr_text = pytesseract.image_to_string(img, lang="kor+eng")
                    text += "\n" + ocr_text
                except Exception as e:
                    print(f"OCR ì‹¤íŒ¨ (í˜ì´ì§€ {page_num}): {e}")
            
            full_text += f"\n=== í˜ì´ì§€ {page_num} ===\n{text}"
        
        return full_text
    except Exception as e:
        return f"âŒ PDF ì˜¤ë¥˜: {e}"

def extract_text_from_hwp(path):
    try:
        import olefile
        if not olefile.isOleFile(path):
            return "âŒ ì˜¬ë°”ë¥¸ HWP íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤."
        
        ole = olefile.OleFileIO(path)
        text = ""
        
        # PrvText ìŠ¤íŠ¸ë¦¼ í™•ì¸ (ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸)
        if ole.exists('PrvText'):
            with ole.openstream('PrvText') as stream:
                text = stream.read().decode('utf-16', errors='ignore')
                if text.strip():
                    return text.strip()
        
        # BodyText ìŠ¤íŠ¸ë¦¼ í™•ì¸ (ë³¸ë¬¸ í…ìŠ¤íŠ¸)
        for i in range(0, 10):  # ì—¬ëŸ¬ ê°œì˜ BodyText ì„¹ì…˜ì´ ìˆì„ ìˆ˜ ìˆìŒ
            section_name = f'BodyText/Section{i}'
            if ole.exists(section_name):
                with ole.openstream(section_name) as stream:
                    section_text = stream.read().decode('utf-16', errors='ignore')
                    text += section_text + "\n"
        
        if text.strip():
            return text.strip()
        else:
            return "âŒ HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âŒ HWP ì˜¤ë¥˜: {e}"

def find_pdf_version(base_dir, pdf_name):
    """PDF í´ë”ì—ì„œ PDF ë²„ì „ì˜ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    # PDF í´ë” ë‚´ì—ì„œ ì§ì ‘ ê²€ìƒ‰
    pdf_dir = os.path.join(base_dir, "pdf")
    if os.path.exists(pdf_dir):
        # ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
        pdf_path = os.path.join(pdf_dir, pdf_name)
        if os.path.exists(pdf_path):
            return pdf_path
        
        # text/image í•˜ìœ„ í´ë”ì—ì„œ ê²€ìƒ‰
        for subdir in ["text", "image"]:
            subdir_path = os.path.join(pdf_dir, subdir)
            if os.path.exists(subdir_path):
                pdf_path = os.path.join(subdir_path, pdf_name)
                if os.path.exists(pdf_path):
                    return pdf_path
        
        # íŒŒì¼ëª… ì¼ë¶€ë¡œ ê²€ìƒ‰
        clean_name = pdf_name
        if len(pdf_name) > 8:  # ë‚ ì§œ í”„ë¦¬í”½ìŠ¤ ì œê±°
            clean_name = pdf_name[8:]
            
        for root, _, files in os.walk(pdf_dir):
            for f in files:
                if f.endswith('.pdf') and (clean_name in f or pdf_name in f):
                    return os.path.join(root, f)
    
    return None

def find_file_in_subfolders(base_dir, file_name):
    """í•˜ìœ„ í´ë”ë¥¼ í¬í•¨í•˜ì—¬ íŒŒì¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # 0. PDF ë²„ì „ì´ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸ (HWP íŒŒì¼ì¸ ê²½ìš°)
    if file_name.lower().endswith('.hwp'):
        pdf_name = file_name.replace('.hwp', '.pdf').replace('.HWP', '.pdf')
        pdf_path = find_pdf_version(base_dir, pdf_name)
        if pdf_path:
            print(f"âœ… HWP ëŒ€ì‹  PDF ë²„ì „ ì°¾ìŒ: {os.path.basename(pdf_path)}")
            return pdf_path
    
    # 1. ì •í™•í•œ íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰
    for root, _, files in os.walk(base_dir):
        if file_name in files:
            return os.path.join(root, file_name)
    
    # 2. ë‚ ì§œ í”„ë¦¬í”½ìŠ¤ê°€ ìˆëŠ” ê²½ìš° (ì˜ˆ: 20250730[ê³µê³ ]_2025ë…„...)
    clean_name = file_name
    if len(file_name) > 8:  # ìµœì†Œ 8ìë¦¬ ì´ìƒ (YYYYMMDD)
        clean_name = file_name[8:]
    
    # ëª¨ë“  íŒŒì¼ì„ ê²€ìƒ‰í•˜ì—¬ ë‚ ì§œ í”„ë¦¬í”½ìŠ¤ë¥¼ ì œì™¸í•œ íŒŒì¼ëª…ì´ í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
    for root, _, files in os.walk(base_dir):
        for f in files:
            # ë‚ ì§œ í”„ë¦¬í”½ìŠ¤(8ìë¦¬)ë¥¼ ì œì™¸í•œ ë¶€ë¶„ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if len(f) > 8 and clean_name in f[8:]:
                print(f"âœ… ë‚ ì§œ í”„ë¦¬í”½ìŠ¤ í¬í•¨ íŒŒì¼ ì°¾ìŒ: {f}")
                return os.path.join(root, f)
            # ë˜ëŠ” íŒŒì¼ëª…ì— clean_nameì´ í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
            elif clean_name in f:
                print(f"âœ… ìœ ì‚¬ íŒŒì¼ëª… ì°¾ìŒ: {f}")
                return os.path.join(root, f)
    
    # 3. í™•ì¥ìë§Œ ì¼ì¹˜í•˜ëŠ” íŒŒì¼ ì¤‘ ê°€ì¥ ìœ ì‚¬í•œ ê²ƒ ì°¾ê¸°
    ext = os.path.splitext(file_name)[1].lower()
    if ext:
        best_match = None
        best_score = 0
        for root, _, files in os.walk(base_dir):
            for f in files:
                if f.lower().endswith(ext):
                    # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ì¸¡ì • (ê³µí†µ ë¶€ë¶„ ë¬¸ìì—´ ê¸¸ì´)
                    common_chars = sum(1 for a, b in zip(f.lower(), file_name.lower()) if a == b)
                    if common_chars > best_score:
                        best_score = common_chars
                        best_match = os.path.join(root, f)
        
        if best_match and best_score > len(ext) + 2:  # í™•ì¥ìë³´ë‹¤ ë” ë§ì€ ë¬¸ìê°€ ì¼ì¹˜í•´ì•¼ í•¨
            print(f"âœ… ìœ ì‚¬ë„ ê¸°ë°˜ íŒŒì¼ ì°¾ìŒ: {os.path.basename(best_match)}")
            return best_match
    
    return None

def create_content_hash(title, content, attachments):
    """ê²Œì‹œë¬¼ì˜ ê³ ìœ  í•´ì‹œê°’ì„ ìƒì„±í•˜ì—¬ ì¤‘ë³µ í™•ì¸ìš©ìœ¼ë¡œ ì‚¬ìš©"""
    # ì œëª©, ë‚´ìš©, ì²¨ë¶€íŒŒì¼ëª…ë“¤ì„ í•©ì³ì„œ í•´ì‹œ ìƒì„±
    attachment_names = [att.get('file_name', '') for att in attachments] if attachments else []
    combined_content = f"{title}|{content}|{'|'.join(sorted(attachment_names))}"
    return hashlib.md5(combined_content.encode('utf-8')).hexdigest()

def load_existing_data(json_file):
    """ê¸°ì¡´ JSON íŒŒì¼ì„ ë¡œë“œí•˜ê³  í•´ì‹œê°’ë“¤ì„ ë°˜í™˜"""
    if not os.path.exists(json_file):
        return [], set()
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
        
        # ê¸°ì¡´ ë°ì´í„°ì˜ í•´ì‹œê°’ë“¤ ìƒì„±
        existing_hashes = set()
        for item in existing_data:
            content_hash = create_content_hash(
                item.get('title', ''),
                item.get('content', ''),
                item.get('attachments', [])
            )
            existing_hashes.add(content_hash)
        
        print(f"ğŸ“„ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ: {len(existing_data)}ê°œ í•­ëª©")
        return existing_data, existing_hashes
    except Exception as e:
        print(f"âŒ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return [], set()

def save_data_with_backup(data, json_file):
    """ë°±ì—…ì„ ë§Œë“¤ê³  ìƒˆ ë°ì´í„°ë¥¼ ì €ì¥"""
    # ë°±ì—… íŒŒì¼ ìƒì„±
    if os.path.exists(json_file):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = f"{json_file}.backup_{timestamp}"
        try:
            import shutil
            shutil.copy2(json_file, backup_file)
            print(f"ğŸ“ ë°±ì—… íŒŒì¼ ìƒì„±: {backup_file}")
        except Exception as e:
            print(f"âš ï¸ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
    
    # ìƒˆ ë°ì´í„° ì €ì¥
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ê²½ë¡œ
csv_file = "ë³µì§€ìš©êµ¬_ìë£Œì‹¤.csv"
attachments_dir = "attachments"
output_file = "rag_input_sample.json"

print("ğŸš€ ë³µì§€ìš©êµ¬ ìë£Œì‹¤ ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")

# ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
existing_data, existing_hashes = load_existing_data(output_file)

# CSV íŒŒì¼ ë¡œë“œ
df = pd.read_csv(csv_file)
print(f"ğŸ“Š CSVì—ì„œ {len(df)}ê°œ ê²Œì‹œë¬¼ ë°œê²¬")

# ìƒˆë¡œ ì¶”ê°€ë  ë°ì´í„°
new_data = []
duplicate_count = 0
error_count = 0
processed_count = 0

# ëª¨ë“  ê²Œì‹œë¬¼ ì²˜ë¦¬
for idx, row in df.iterrows():
    processed_count += 1
    print(f"\nğŸ“ ì²˜ë¦¬ ì¤‘ ({processed_count}/{len(df)}): {row['title'][:50]}...")
    
    # content í•„ë“œê°€ ë¹„ì–´ìˆê±°ë‚˜ NaNì¸ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    content = ""
    if isinstance(row["content"], str) and row["content"]:
        content = row["content"]
    
    # ì„ì‹œ ê²Œì‹œë¬¼ ê°ì²´ ìƒì„± (ì¤‘ë³µ í™•ì¸ìš©)
    temp_post = {
        "title": row["title"],
        "url": row["url"],
        "content": content,
        "attachments": []
    }
    
    # ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬
    if isinstance(row["attachments"], str):
        for item in row["attachments"].split("; "):
            if "(" in item:
                try:
                    # íŒŒì¼ëª…ì—ì„œ URL ë¶€ë¶„ ì œê±°
                    file_name = item.split(" (")[0].strip()
                    
                    # í•˜ìœ„ í´ë”ë¥¼ í¬í•¨í•˜ì—¬ íŒŒì¼ ê²€ìƒ‰
                    file_path = find_file_in_subfolders(attachments_dir, file_name)
                    
                    if not file_path:
                        print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}")
                        continue
                    
                    print(f"âœ… íŒŒì¼ ì°¾ìŒ: {os.path.relpath(file_path)}")
                    
                    ext = os.path.splitext(file_path)[1].lower()
                    if ext == ".pdf":
                        text = extract_text_from_pdf(file_path)
                    elif ext == ".hwp":
                        # HWP íŒŒì¼ì¸ ê²½ìš° PDF ë²„ì „ì´ ìˆëŠ”ì§€ í™•ì¸
                        pdf_path = file_path.replace(".hwp", ".pdf")
                        if os.path.exists(pdf_path):
                            print(f"âœ… HWP ëŒ€ì‹  PDF ë²„ì „ ì‚¬ìš©: {os.path.basename(pdf_path)}")
                            text = extract_text_from_pdf(pdf_path)
                        else:
                            # PDF í´ë”ì—ì„œ ë™ì¼í•œ ì´ë¦„ì˜ PDF íŒŒì¼ ì°¾ê¸° ì‹œë„
                            pdf_dir = os.path.join(attachments_dir, "pdf")
                            pdf_filename = os.path.basename(file_path).replace(".hwp", ".pdf")
                            pdf_path_in_dir = os.path.join(pdf_dir, pdf_filename)
                            
                            if os.path.exists(pdf_path_in_dir):
                                print(f"âœ… PDF í´ë”ì—ì„œ ëŒ€ì²´ íŒŒì¼ ì°¾ìŒ: {pdf_filename}")
                                text = extract_text_from_pdf(pdf_path_in_dir)
                            else:
                                text = extract_text_from_hwp(file_path)
                    else:
                        text = f"âš ï¸ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}"
                    
                    temp_post["attachments"].append({
                        "file_name": os.path.basename(file_path),
                        "text": text
                    })
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    error_count += 1
    
    # ì¤‘ë³µ í™•ì¸
    content_hash = create_content_hash(
        temp_post["title"],
        temp_post["content"],
        temp_post["attachments"]
    )
    
    if content_hash in existing_hashes:
        print(f"ğŸ”„ ì¤‘ë³µ ë°ì´í„° ìŠ¤í‚µ: {temp_post['title'][:30]}...")
        duplicate_count += 1
        continue
    
    # ìƒˆ ë°ì´í„°ì— ì¶”ê°€
    new_data.append(temp_post)
    existing_hashes.add(content_hash)  # ì´í›„ ì¤‘ë³µ í™•ì¸ì„ ìœ„í•´ ì¶”ê°€
    print(f"âœ… ìƒˆ ë°ì´í„° ì¶”ê°€: {temp_post['title'][:30]}...")

# ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° í•©ì¹˜ê¸°
final_data = existing_data + new_data

# ë°ì´í„° ì €ì¥
save_data_with_backup(final_data, output_file)

print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
print(f"ğŸ“Š ì „ì²´ ê²Œì‹œë¬¼: {len(df)}ê°œ")
print(f"âœ… ìƒˆë¡œ ì¶”ê°€: {len(new_data)}ê°œ")
print(f"ğŸ”„ ì¤‘ë³µ ìŠ¤í‚µ: {duplicate_count}ê°œ")
print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error_count}ê°œ")
print(f"ğŸ“ ìµœì¢… ë°ì´í„°: {len(final_data)}ê°œ")
print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")

# ì²¨ë¶€íŒŒì¼ í†µê³„
total_attachments = sum(len(item.get('attachments', [])) for item in final_data)
print(f"ğŸ“ ì´ ì²¨ë¶€íŒŒì¼: {total_attachments}ê°œ")

