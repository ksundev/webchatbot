from flask import Flask, render_template, request, jsonify, session, redirect, url_for
import os
import re
import csv
from datetime import datetime, timedelta
from typing import Dict, Any
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from dotenv import load_dotenv
import json

app = Flask(__name__)
app.secret_key = 'your-secret-key-here'  # ì„¸ì…˜ì„ ìœ„í•œ ì‹œí¬ë¦¿ í‚¤

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê´€ë¦¬ì ì„¤ì •
ADMIN_PASSWORD = "1234"  # ì‹¤ì œ ì‚¬ìš©ì‹œ ë” ë³µì¡í•œ ë¹„ë°€ë²ˆí˜¸ë¡œ ë³€ê²½

# PDF ê²½ë¡œì™€ ë²¡í„° ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
JSON_PATH = "rag_input_sample.json"
VECTOR_DIR = "vectorstore"
embeddings = OpenAIEmbeddings()

# ê´€ë¦¬ì ì¸ì¦ ë°ì½”ë ˆì´í„°
def admin_required(f):
    def decorated_function(*args, **kwargs):
        if not session.get('admin_logged_in'):
            return redirect(url_for('admin_login'))
        return f(*args, **kwargs)
    decorated_function.__name__ = f.__name__
    return decorated_function

# ì±—ë´‡ ê°€ë“œë ˆì¼ í´ë˜ìŠ¤
class ChatbotGuardrails:
    def __init__(self):
        # ë³µì§€ìš©êµ¬ ê´€ë ¨ í‚¤ì›Œë“œ
        self.welfare_keywords = [
            'ë³µì§€', 'ìš©êµ¬', 'ì‹ ì²­', 'ë“±ê¸‰', 'ë¶€ë‹´', 'ìê²©', 'í’ˆëª©', 'ë³´ì¡°', 'ì§€ì›',
            'ë…¸ì¸', 'ì¥ì• ', 'ì˜ë£Œ', 'ì¬í™œ', 'ë³´ì¥', 'ìˆ˜ê¸‰', 'ê¸‰ì—¬', 'ì„œë¹„ìŠ¤',
            'ìš•ì°½', 'ë§¤íŠ¸ë¦¬ìŠ¤', 'ë°©ì„', 'ë³´í–‰ê¸°', 'íœ ì²´ì–´', 'ì¹¨ëŒ€', 'ë³€ê¸°', 'ëª©ìš•',
            'ì‚°ì†Œ', 'í˜¸í¡ê¸°', 'ë°œìƒê¸°', 'ì¹˜ë£Œ', 'ì˜ë£Œê¸°ê¸°', 'ë³´ì¥êµ¬'
        ]
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜ (ë” êµ¬ì²´ì ìœ¼ë¡œ)
        self.category_keywords = {
            'ì‹ ì²­ë°©ë²•': ['ì‹ ì²­ë°©ë²•', 'ì‹ ì²­ ë°©ë²•', 'ì‹ ì²­ ì ˆì°¨', 'ì‹ ì²­ ì„œë¥˜', 'ì‹ ì²­ì„œ', 'ì œì¶œ', 'ì ‘ìˆ˜', 'ì²˜ë¦¬', 'ì–´ë–»ê²Œ ì‹ ì²­', 'ì‹ ì²­í•˜ë ¤ë©´'],
            'í’ˆëª©': ['í’ˆëª©', 'ì¢…ë¥˜', 'ì œí’ˆ', 'ê¸°êµ¬', 'ì¥ë¹„', 'ë³´ì¡°ê¸°êµ¬', 'ì¬í™œìš©í’ˆ', 'ì–´ë–¤ ê²ƒë“¤', 'í’ˆëª©ì—ëŠ”', 'ì¢…ë¥˜ì—ëŠ”'],
            'ë“±ê¸‰ì‹ ì²­ì¡°ê±´': ['ë“±ê¸‰', 'ë“±ê¸‰ ì‹ ì²­', 'ë“±ê¸‰ ì¡°ê±´', 'ë“±ê¸‰ ê¸°ì¤€', 'ë“±ê¸‰ íŒì •', 'ë“±ê¸‰ ì¸ì •', 'ë“±ê¸‰ ìš”ê±´', 'ìê²©ì¡°ê±´', 'ì‹ ì²­ ì¡°ê±´', 'ì¡°ê±´'],
            'ë³¸ì¸ë¶€ë‹´ë¥ ': ['ë³¸ì¸ë¶€ë‹´ë¥ ', 'ë¶€ë‹´ë¥ ', 'ë³¸ì¸ ë¶€ë‹´', 'ë¹„ìš©', 'ê¸ˆì•¡', 'ìš”ê¸ˆ', 'ê°€ê²©', 'ì–¼ë§ˆ', 'ë¹„ìš©', 'í• ì¸', 'ë¶€ë‹´'],
            'ìê²©í™•ì¸': ['ìê²©', 'ìê²© í™•ì¸', 'í™•ì¸', 'ì¡°ì‚¬', 'ê²€í† ', 'ì‹¬ì‚¬', 'í‰ê°€', 'íŒë‹¨', 'ê°€ëŠ¥í•œì§€', 'ì‹ ì²­ ê°€ëŠ¥']
        }
        
        # ê¸ˆì§€ í‚¤ì›Œë“œ (ëª…ë°±íˆ ë¶€ì ì ˆí•œ ë‚´ìš©ë§Œ)
        self.forbidden_keywords = [
            'ìš•ì„¤', 'ë¹„ì†ì–´', 'ìŒë€', 'ì„ ì •ì ', 'í­ë ¥', 'í˜ì˜¤', 'ì°¨ë³„', 'ì •ì¹˜', 'ì¢…êµ'
        ]
        
        # ì˜ˆì‹œ ì§ˆë¬¸ë“¤ (ì´ˆê¸° ê°€ì´ë“œë¼ì¸)
        self.example_questions = [
            "ë³µì§€ìš©êµ¬ ì‹ ì²­ ë°©ë²•ì´ ê¶ê¸ˆí•´ìš”",
            "ë³µì§€ìš©êµ¬ í’ˆëª©ì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?",
            "ë³µì§€ìš©êµ¬ ë“±ê¸‰ ì‹ ì²­ ì¡°ê±´ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ë³µì§€ìš©êµ¬ ë³¸ì¸ë¶€ë‹´ë¥ ì€ ì–¼ë§ˆì¸ê°€ìš”?",
            "ë³µì§€ìš©êµ¬ ìê²© í™•ì¸ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
            "ë³µì§€ìš©êµ¬ ì‹ ì²­ ì„œë¥˜ëŠ” ë¬´ì—‡ì´ í•„ìš”í•œê°€ìš”?",
            "ë³µì§€ìš©êµ¬ ìˆ˜ê¸‰ì ìê²©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "ë³µì§€ìš©êµ¬ ê¸‰ì—¬ ì„œë¹„ìŠ¤ëŠ” ì–´ë–»ê²Œ ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?"
        ]
        
        # ì‚¬ìš©ìë³„ ë§ˆì§€ë§‰ ì§ˆë¬¸ ì¶”ì  (ì¤‘ë³µ ë°©ì§€ìš©)
        self.user_last_questions = {}
        self.user_last_timestamps = {}
    
    def validate_question(self, question: str, user_id: str = "default") -> Dict[str, Any]:
        """ì§ˆë¬¸ ìœ íš¨ì„± ê²€ì¦"""
        question = question.strip()
        
        # 1. ê¸¸ì´ ê²€ì¦
        if len(question) <= 3:
            return {
                'valid': False,
                'message': 'ì§ˆë¬¸ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. (ì˜ˆ: "ë³µì§€ìš©êµ¬ ì‹ ì²­ ë°©ë²•ì´ ê¶ê¸ˆí•´ìš”")',
                'examples': self.get_random_examples(3)
            }
        
        # 2. ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ ê²€ì¦
        meaningless_patterns = [r'^[ì•„ì–´ìŒê·¸ì €]+$', r'^[?!]+$', r'^[ê°€-í£]{1,2}$']
        for pattern in meaningless_patterns:
            if re.match(pattern, question):
                return {
                    'valid': False,
                    'message': 'êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”. ë³µì§€ìš©êµ¬ì™€ ê´€ë ¨ëœ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!',
                    'examples': self.get_random_examples(3)
                }
        
        # 3. ê¸ˆì§€ í‚¤ì›Œë“œ ê²€ì¦
        for keyword in self.forbidden_keywords:
            if keyword in question:
                return {
                    'valid': False,
                    'message': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ë…¸ì¸ë³µì§€ìš©êµ¬ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•  ìˆ˜ ìˆì–´ìš”. ë³µì§€ìš©êµ¬ì™€ ê´€ë ¨ëœ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!',
                    'examples': self.get_random_examples(3)
                }
        
        # 4. GPT ê¸°ë°˜ ê´€ë ¨ì„± ê²€ì¦
        relevance_check = self.check_welfare_relevance(question)
        if not relevance_check['is_relevant']:
            return {
                'valid': False,
                'message': relevance_check['message'],
                'examples': self.get_random_examples(3)
            }
        
        return {'valid': True, 'message': 'ì§ˆë¬¸ì´ ìœ íš¨í•©ë‹ˆë‹¤.'}
    
    def check_welfare_relevance(self, question: str) -> Dict[str, Any]:
        """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì§€ìš©êµ¬ ê´€ë ¨ì„± ê²€ì¦"""
        try:
            from langchain_openai import ChatOpenAI
            
            # ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ ê°„ë‹¨í•œ ëª¨ë¸ ì‚¬ìš©
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, max_tokens=50)
            
            relevance_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì´ ë…¸ì¸ë³µì§€ìš©êµ¬ì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ë…¸ì¸ë³µì§€ìš©êµ¬ë€: ë…¸ì¸ì˜ ì¼ìƒìƒí™œì„ ë•ëŠ” ì˜ë£Œê¸°ê¸°ë‚˜ ë³´ì¡°ê¸°êµ¬ (íœ ì²´ì–´, ì¹¨ëŒ€, ë³´í–‰ê¸°, ìš•ì°½ë°©ì§€ìš©í’ˆ, ì•ˆì „ì†ì¡ì´ ë“±)
ê´€ë ¨ ì£¼ì œ: ë³µì§€ìš©êµ¬ ì‹ ì²­, ë“±ê¸‰, ë¹„ìš©, í’ˆëª©, ìê²©ì¡°ê±´, ì‚¬ìš©ë²•, ëŒ€ì—¬/êµ¬ì… ë“±

ì§ˆë¬¸: "{question}"

ë‹µë³€ í˜•ì‹:
- ê´€ë ¨ ìˆìŒ: "YES"
- ê´€ë ¨ ì—†ìŒ: "NO"

ë‹µë³€:"""

            response = llm.invoke(relevance_prompt)
            result = response.content.strip().upper()
            
            if "YES" in result:
                return {
                    'is_relevant': True,
                    'message': 'ë³µì§€ìš©êµ¬ ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤.'
                }
            else:
                return {
                    'is_relevant': False,
                    'message': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ë…¸ì¸ë³µì§€ìš©êµ¬ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ë³µì§€ìš©êµ¬ ì‹ ì²­, í’ˆëª©, ë¹„ìš©, ìê²©ì¡°ê±´ ë“±ì— ëŒ€í•´ì„œë§Œ ë‹µë³€í•  ìˆ˜ ìˆì–´ìš”. ë³µì§€ìš©êµ¬ì™€ ê´€ë ¨ëœ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!'
                }
                
        except Exception as e:
            print(f"ê´€ë ¨ì„± ê²€ì¦ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ í—ˆìš© (ê¸°ì¡´ RAGì—ì„œ ì²˜ë¦¬)
            return {
                'is_relevant': True,
                'message': 'ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì§€ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.'
            }
    
    def verify_and_correct_answer(self, question: str, answer: str) -> str:
        """ë‹µë³€ì„ ê²€ì¦í•˜ê³  í•„ìš”ì‹œ êµì •"""
        try:
            from langchain_openai import ChatOpenAI
            
            # ë¹ ë¥¸ ê²€ì¦ìš© ëª¨ë¸
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, max_tokens=150)
            
            verify_prompt = f"""
ë‹¤ìŒ ë‹µë³€ì— ëª…ë°±í•œ ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ë§Œ ê²€ì¦í•´ì£¼ì„¸ìš”. ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

ê²€ì¦ ê¸°ì¤€:
1. ì „ë™íœ ì²´ì–´ë¥¼ ë³µì§€ìš©êµ¬ë¼ê³  í–ˆëŠ”ê°€? (ì˜¤ë¥˜ - ì „ë™íœ ì²´ì–´ëŠ” ì˜ë£Œê¸°ê¸°)
2. ë³µì§€ìš©êµ¬ê°€ ì•„ë‹Œ ê²ƒì„ ë³µì§€ìš©êµ¬ë¼ê³  í–ˆëŠ”ê°€?
3. ëª…ë°±íˆ í‹€ë¦° ì‚¬ì‹¤ì´ ìˆëŠ”ê°€?

ì§ˆë¬¸: "{question}"
ë‹µë³€: "{answer}"

ê²€ì¦ ê²°ê³¼ (ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ):
- "PASS" (ë‹µë³€ì— ëª…ë°±í•œ ì˜¤ë¥˜ ì—†ìŒ)
- "BLOCK: [ê°„ë‹¨í•œ ì´ìœ ]" (ëª…ë°±í•œ ì˜¤ë¥˜ ë°œê²¬)

ê²€ì¦:"""

            response = llm.invoke(verify_prompt)
            result = response.content.strip()
            
            if result.startswith("BLOCK:"):
                # ì˜¤ë¥˜ ë°œê²¬ ì‹œ ì˜¬ë°”ë¥¸ ì •ë³´ë¡œ ì¬ë‹µë³€ ì‹œë„
                reason = result.replace("BLOCK:", "").strip()
                print(f"ğŸš¨ ë‹µë³€ ì˜¤ë¥˜ ë°œê²¬: {reason}")
                print(f"ğŸ”„ ì˜¬ë°”ë¥¸ ì •ë³´ë¡œ ì¬ë‹µë³€ ì‹œë„...")
                
                # ì˜¬ë°”ë¥¸ ì •ë³´ë¡œ ë‹¤ì‹œ ë‹µë³€ ìƒì„±
                corrected_answer = self.get_corrected_answer(question)
                return corrected_answer
            else:
                # ê²€ì¦ í†µê³¼ - ì›ë³¸ ë‹µë³€ ì‚¬ìš©
                return answer
                
        except Exception as e:
            print(f"ë‹µë³€ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            # ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë‹µë³€ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return answer
    

    
    def classify_question(self, question: str, status: str = 'success') -> str:
        """ì§ˆë¬¸ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        if status == 'fallback' or status == 'blocked':
            return 'ì°¨ë‹¨ëœì§ˆë¬¸'
        
        question_lower = question.lower()
        category_scores = {}
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°
        for category, keywords in self.category_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in question_lower:
                    score += 1
            category_scores[category] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
        if category_scores:
            best_category = max(category_scores, key=category_scores.get)
            if category_scores[best_category] > 0:
                return best_category
        
        # ëª…í™•í•œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìœ¼ë©´ ê¸°íƒ€ë¡œ ë¶„ë¥˜
        return 'ê¸°íƒ€'
    
    def check_duplicate_question(self, question: str, user_id: str) -> Dict[str, Any]:
        """ì¤‘ë³µ ì§ˆë¬¸ ê²€ì¦ (ì„ì‹œ ë¹„í™œì„±í™”)"""
        return {'valid': True, 'message': 'ì¤‘ë³µ ê²€ì¦ í†µê³¼'}
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        return len(intersection) / len(union) if union else 0
    
    def get_random_examples(self, count: int = 3) -> list:
        """ëœë¤ ì˜ˆì‹œ ì§ˆë¬¸ ë°˜í™˜"""
        import random
        return random.sample(self.example_questions, min(count, len(self.example_questions)))
    
    def get_welcome_examples(self) -> list:
        """í™˜ì˜ ì˜ˆì‹œ ì§ˆë¬¸ ë°˜í™˜"""
        return self.example_questions[:5]
    
    def get_fallback_response(self, error_type: str) -> str:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ì²´ ì‘ë‹µ"""
        fallback_responses = {
            'search_error': 'ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ê²€ìƒ‰ì— ë¬¸ì œê°€ ìˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
            'api_error': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ìˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
            'general_error': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
        }
        return fallback_responses.get(error_type, fallback_responses['general_error'])

# ê°€ë“œë ˆì¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
guardrails = ChatbotGuardrails()



def save_chat_log(question, answer, is_fallback=False):
    """ì±„íŒ… ë¡œê·¸ë¥¼ CSV íŒŒì¼ì— ì €ì¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    status = "fallback" if is_fallback else "success"
    category = guardrails.classify_question(question, status)
    
    # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ì—ì„œ CSV íŒŒì¼ ì°¾ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    csv_path = os.path.join(current_dir, 'chat_log.csv')
    
    # CSV íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ì™€ í•¨ê»˜ ìƒì„±
    file_exists = os.path.exists(csv_path)
    
    with open(csv_path, 'a', newline='', encoding='utf-8-sig') as file:
        writer = csv.writer(file)
        if not file_exists:
            writer.writerow(['timestamp', 'question', 'answer', 'status', 'category'])
        writer.writerow([timestamp, question, answer, status, category])

def save_feedback_log(question, answer, feedback_type, user_id):
    """í”¼ë“œë°± ë¡œê·¸ë¥¼ ë³„ë„ CSV íŒŒì¼ì— ì €ì¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ì—ì„œ í”¼ë“œë°± ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    feedback_path = os.path.join(current_dir, 'feedback_log.csv')
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë”ì™€ í•¨ê»˜ ìƒì„±
    file_exists = os.path.exists(feedback_path)
    
    with open(feedback_path, 'a', newline='', encoding='utf-8-sig') as file:
        writer = csv.writer(file)
        if not file_exists:
            writer.writerow(['timestamp', 'question', 'answer', 'feedback_type', 'user_id'])
        writer.writerow([timestamp, question, answer, feedback_type, user_id])

def read_feedback_logs(limit=None):
    """í”¼ë“œë°± ë¡œê·¸ë¥¼ ì½ì–´ì˜¤ê¸°"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    feedback_path = os.path.join(current_dir, 'feedback_log.csv')
    
    if not os.path.exists(feedback_path):
        return []
    
    logs = []
    try:
        with open(feedback_path, 'r', encoding='utf-8-sig') as file:
            reader = csv.DictReader(file)
            for row in reader:
                logs.append({
                    'timestamp': row.get('timestamp', ''),
                    'question': row.get('question', ''),
                    'answer': row.get('answer', ''),
                    'feedback_type': row.get('feedback_type', ''),
                    'user_id': row.get('user_id', '')
                })
        
        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
        logs.reverse()
        
        if limit:
            logs = logs[:limit]
        
        return logs
    except Exception as e:
        return []

def read_chat_logs(limit=None, category=None):
    """ì±„íŒ… ë¡œê·¸ë¥¼ ì½ì–´ì˜¤ê¸°"""
    # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ì—ì„œ CSV íŒŒì¼ ì°¾ê¸°
    current_dir = os.path.dirname(os.path.abspath(__file__))
    csv_path = os.path.join(current_dir, 'chat_log.csv')
    
    if not os.path.exists(csv_path):
        return []
    
    logs = []
    try:
        with open(csv_path, 'r', encoding='utf-8-sig') as file:
            reader = csv.DictReader(file)
            for row in reader:
                # HTML í…œí”Œë¦¿ì—ì„œ í•„ìš”í•œ ëª¨ë“  í•„ë“œ í¬í•¨
                simple_log = {
                    'timestamp': row.get('timestamp', ''),
                    'question': row.get('question', ''),
                    'answer': row.get('answer', ''),
                    'status': row.get('status', 'success'),
                    'category': row.get('category', 'ê¸°íƒ€')
                }
                
                # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                if category and category != 'all' and simple_log['category'] != category:
                    continue
                    
                logs.append(simple_log)
        
        # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
        logs.reverse()
        
        if limit:
            logs = logs[:limit]
        
        return logs
    except Exception as e:
        return []

# init_vectorstore í•¨ìˆ˜ ìˆ˜ì •
def init_vectorstore():
    if os.path.exists(VECTOR_DIR):
        vectorstore = FAISS.load_local(VECTOR_DIR, embeddings, allow_dangerous_deserialization=True)
        print("âœ… ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
    else:
        print("ğŸ› ï¸ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
        
        # JSON íŒŒì¼ ë¡œë“œ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        json_path = os.path.join(current_dir, JSON_PATH)
        print(f"ğŸ“ JSON ê²½ë¡œ: {json_path}")
        print(f"ğŸ“ JSON íŒŒì¼ ì¡´ì¬: {os.path.exists(json_path)}")
        
        # JSON íŒŒì¼ ì½ê¸°
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ë¬¸ì„œ ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
        vectorstore = None
        batch_size = 5  # í•œ ë²ˆì— 5ê°œì”© ì²˜ë¦¬
        
        for i in range(0, len(data), batch_size):
            batch = data[i:i+batch_size]
            print(f"ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1}/{(len(data)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ë¬¸ì„œ)")
            
            docs = []
            for item in batch:
                # ì²¨ë¶€íŒŒì¼ ë‚´ìš© ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸´ íŒŒì¼ì€ ì˜ë¼ëƒ„)
                content = f"ì œëª©: {item['title']}\n\n"
                content += f"URL: {item['url']}\n\n"
                
                # ë‚´ìš© ê¸¸ì´ ì œí•œ (10,000ìë¡œ ì œí•œ)
                main_content = item['content'] or ''
                content += f"ë‚´ìš©: {main_content}\n\n"
                
                # ì²¨ë¶€íŒŒì¼ ë‚´ìš© ì¶”ê°€ (ê° íŒŒì¼ë‹¹ 5,000ìë¡œ ì œí•œ)
                if 'attachments' in item and item['attachments']:
                    for attachment in item['attachments']:
                        content += f"ì²¨ë¶€íŒŒì¼: {attachment['file_name']}\n\n"
                        file_text = attachment['text'] or ''
                        content += f"íŒŒì¼ë‚´ìš©: {file_text}\n\n"
                
                # Document ê°ì²´ ìƒì„±
                from langchain_core.documents import Document
                doc = Document(page_content=content, metadata={"source": item['title']})
                docs.append(doc)
            
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=120)
            split_documents = text_splitter.split_documents(docs)
            print(f"âœ‚ï¸ ë°°ì¹˜ ë¶„í•  ì™„ë£Œ: {len(split_documents)} ì²­í¬")
            
            # ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë˜ëŠ” ì¶”ê°€
            try:
                if vectorstore is None:
                    vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)
                    print(f"âœ… ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±")
                else:
                    vectorstore.add_documents(split_documents)
                    print(f"âœ… ë°°ì¹˜ ì¶”ê°€ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                if "max_tokens_per_request" in str(e):
                    print("ğŸ”„ ì²­í¬ í¬ê¸°ë¥¼ ë” ì¤„ì—¬ì„œ ì¬ì‹œë„...")
                    # ì²­í¬ í¬ê¸°ë¥¼ ë” ì¤„ì—¬ì„œ ì¬ì‹œë„
                    smaller_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)
                    split_documents = smaller_splitter.split_documents(docs)
                    if vectorstore is None:
                        vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)
                    else:
                        vectorstore.add_documents(split_documents)
                    print(f"âœ… ì‘ì€ ì²­í¬ë¡œ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
                else:
                    raise e
        
        print(f"ğŸ“„ ì „ì²´ JSON ë¡œë“œ ì™„ë£Œ: {len(data)} ë¬¸ì„œ")
        
        # ë²¡í„°ìŠ¤í† ì–´ ì €ì¥
        if vectorstore:
            vectorstore.save_local(VECTOR_DIR)
            print("âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ")
        else:
            raise Exception("ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨")
    
    return vectorstore

# ì²´ì¸ ì´ˆê¸°í™”
def filter_relevant_context(question: str, retrieved_docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œ ì¤‘ ì§ˆë¬¸ê³¼ ì‹¤ì œë¡œ ê´€ë ¨ìˆëŠ” ê²ƒë§Œ í•„í„°ë§"""
    try:
        from langchain_openai import ChatOpenAI
        
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, max_tokens=100)
        
        filtered_docs = []
        
        for doc in retrieved_docs:
            # ê° ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆëŠ”ì§€ ê²€ì¦
            filter_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë¬¸ì„œ ë‚´ìš©ì´ ì‹¤ì œë¡œ ê´€ë ¨ì´ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: "{question}"
ë¬¸ì„œ ë‚´ìš©: "{doc.page_content[:500]}..."

ë‹µë³€: "ê´€ë ¨ìˆìŒ" ë˜ëŠ” "ê´€ë ¨ì—†ìŒ"
"""
            
            response = llm.invoke(filter_prompt)
            result = response.content.strip()
            
            if "ê´€ë ¨ìˆìŒ" in result:
                filtered_docs.append(doc)
                
        return filtered_docs[:10]  # ìµœëŒ€ 10ê°œë§Œ ì‚¬ìš©
        
    except Exception as e:
        print(f"ì»¨í…ìŠ¤íŠ¸ í•„í„°ë§ ì˜¤ë¥˜: {e}")
        return retrieved_docs[:10]  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ì‚¬ìš©

def init_chain():
    vectorstore = init_vectorstore()
    retriever = vectorstore.as_retriever(search_kwargs={"k": 15})
    
    prompt = PromptTemplate.from_template(
        """ë„ˆëŠ” ë…¸ì¸ë³µì§€ìš©êµ¬ ë° ì¥ì• ì¸ë³´ì¡°ê¸°ê¸° ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì´ì•¼. 


ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì œê³µëœ ìë£Œ(context)ë¥¼ ì°¸ê³ í•´ì„œ, ì–´ë¥´ì‹ ë“¤ì´ ì´í•´í•˜ê¸° ì‰½ê³  ì½ê¸° í¸í•˜ê²Œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì¤˜.

ë‹µë³€ ì‘ì„± ì‹œ ë°˜ë“œì‹œ ë‹¤ìŒ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì •í™•íˆ ì‚¬ìš©í•´ì£¼ì„¸ìš”:

**1. ì œëª©ê³¼ ì„¹ì…˜:**
- ë©”ì¸ ì œëª©: **ì œëª©**
- ì„¹ì…˜ ì œëª©: **ì„¹ì…˜ëª…:**
- ì˜ˆì‹œ: **ë³¸ì¸ë¶€ë‹´ë¥ :** ë˜ëŠ” **ì‹ ì²­ ìê²©:**

**2. ê°•ì¡° í‘œí˜„:**
- ì¤‘ìš”í•œ ìˆ«ìë‚˜ í‚¤ì›Œë“œ: **15%** ë˜ëŠ” **ë³µì§€ìš©êµ¬**
- í•µì‹¬ ë‚´ìš©: **ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­**

**3. ëª©ë¡ê³¼ ì²´í¬ë¦¬ìŠ¤íŠ¸:**
- ì¼ë°˜ ëª©ë¡: â€¢ í•­ëª©
- ì²´í¬ë¦¬ìŠ¤íŠ¸: âœ… í•­ëª© (ì¤„ë°”ê¿ˆ ì—†ì´)
- ê²½ê³ ì‚¬í•­: âš ï¸ í•­ëª© (ì¤„ë°”ê¿ˆ ì—†ì´)
- ì—°ë½ì²˜: ğŸ“ í•­ëª© (ì¤„ë°”ê¿ˆ ì—†ì´)
- ë²ˆí˜¸ ëª©ë¡: 1ï¸âƒ£ í•­ëª© (ì¤„ë°”ê¿ˆ ì—†ì´)

**4. êµ¬ì¡°í™”ëœ ë‹µë³€ ì˜ˆì‹œ:**
**ì„¹ì…˜ ì œëª©:**

âœ… **í•­ëª© 1:** **ë‚´ìš©**

âœ… **í•­ëª© 2:** **ë‚´ìš©**

âš ï¸ **ì£¼ì˜ì‚¬í•­:** êµ¬ì²´ì ì¸ ì •ë³´ëŠ” ì œê³µëœ ìë£Œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

ğŸ“ **ë¬¸ì˜:** ê´€ë ¨ ê¸°ê´€ì— í™•ì¸í•´ ì£¼ì„¸ìš”.

**ì£¼ì˜:** ìœ„ëŠ” í˜•ì‹ ì˜ˆì‹œì´ë©°, ì‹¤ì œ ë‹µë³€ì—ì„œëŠ” ì œê³µëœ context ì •ë³´ë¥¼ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”.

**ì¤‘ìš”:** ë‹µë³€ì€ ë°˜ë“œì‹œ ì œê³µëœ context ì •ë³´ì— ê¸°ë°˜í•´ì•¼ í•˜ë©°, ì •í™•ì„±ì„ ìµœìš°ì„ ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.

**5. ì–´ë¥´ì‹  ì¹œí™”ì  í‘œí˜„:**
- ì¡´ëŒ“ë§ ì‚¬ìš©
- ë³µì¡í•œ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ ì„¤ëª…
- ì¶©ë¶„íˆ ìì„¸í•˜ê³  ì™„ì „í•œ ë‹µë³€ ì œê³µ
- ë‹µë³€ì„ ì¤‘ê°„ì— ëŠì§€ ë§ê³  ì™„ì „íˆ ë§ˆë¬´ë¦¬í•˜ê¸°

**6. ì•ˆì „ì¥ì¹˜:**
- ì˜ ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë‹ˆ ê³µë‹¨ì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”"ë¼ê³  ì•ˆë‚´
- ë³µì§€ìš©êµ¬ ëª…ì¹­ì´ë‚˜ ìˆ˜ê¸‰ ì¡°ê±´ì€ ëª…í™•í•˜ê²Œ ë§í•´ì¤˜

**7. ë‹µë³€ ì™„ì„±ë„:**
- ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ì™„ì „í•œ ë‹µë³€ ì œê³µ
- ë‹µë³€ì´ ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šë„ë¡ ì£¼ì˜
- ë‚´ìš©ì´ ë§ë”ë¼ë„ ë‹µë³€ì„ ì™„ì „íˆ ë§ˆë¬´ë¦¬í•˜ê¸°

ë‹µë³€ ì‘ì„± ì‹œ ë°˜ë“œì‹œ ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”:
1. ê° ì„¹ì…˜ë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ ë„£ì–´ì£¼ì„¸ìš”
2. ëª©ë¡ì€ ê° í•­ëª©ë§ˆë‹¤ ì¤„ë°”ê¿ˆì„ ë„£ì–´ì£¼ì„¸ìš”
3. ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì„ ì •í™•íˆ ì‚¬ìš©í•´ì£¼ì„¸ìš” (**êµµì€ ê¸€ì”¨**, âœ…, âš ï¸ ë“±)
4. ì½ê¸° ì‰½ë„ë¡ ì ì ˆí•œ ê³µë°±ì„ ë„£ì–´ì£¼ì„¸ìš”
5. ë‹µë³€ì€ ë°˜ë“œì‹œ ëê¹Œì§€ ì™„ì„±í•´ì£¼ì„¸ìš”


#Context: 
{context}

#Question:
{question}

#Answer:"""
    )
    
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0, model_kwargs={"max_completion_tokens": 2000} )
    
    def get_filtered_context(question):
        docs = retriever.get_relevant_documents(question)
        filtered = filter_relevant_context(question, docs)
        return "\n\n".join([doc.page_content for doc in filtered])
    
    chain = (
        {"context": get_filtered_context, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    return chain

# ì „ì—­ ë³€ìˆ˜ë¡œ ì²´ì¸ ì €ì¥
chain = init_chain()

@app.route('/')
def home():
    return render_template('chat.html')

@app.route('/admin/login', methods=['GET', 'POST'])
def admin_login():
    if request.method == 'POST':
        password = request.form.get('password')
        if password == ADMIN_PASSWORD:
            session['admin_logged_in'] = True
            return redirect(url_for('admin_logs'))
        else:
            return render_template('admin_login.html', error='ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.')
    return render_template('admin_login.html')

@app.route('/admin/logout')
def admin_logout():
    session.pop('admin_logged_in', None)
    return redirect(url_for('home'))

@app.route('/admin/logs')
@admin_required
def admin_logs():
    logs = read_chat_logs(limit=100)
    feedback_logs = read_feedback_logs(limit=100)
    
    # ê°„ë‹¨í•œ í†µê³„ ê³„ì‚°
    total_questions = len(logs)
    
    # í”¼ë“œë°± í†µê³„ ê³„ì‚°
    like_count = len([f for f in feedback_logs if f['feedback_type'] == 'like'])
    dislike_count = len([f for f in feedback_logs if f['feedback_type'] == 'dislike'])
    
    return render_template('admin_logs.html', 
                         logs=logs, 
                         feedback_logs=feedback_logs,
                         total_questions=total_questions,
                         successful=total_questions,
                         blocked_errors=0,
                         success_rate=100.0,
                         categories={},
                         like_count=like_count,
                         dislike_count=dislike_count)

@app.route('/admin/api/logs')
@admin_required
def admin_api_logs():
    category = request.args.get('category')
    logs = read_chat_logs(limit=100, category=category)
    return jsonify({'logs': logs})

@app.route('/admin/api/feedback')
@admin_required
def admin_api_feedback():
    feedback_type = request.args.get('type')
    feedback_logs = read_feedback_logs()
    
    if feedback_type and feedback_type in ['like', 'dislike']:
        feedback_logs = [f for f in feedback_logs if f['feedback_type'] == feedback_type]
    
    return jsonify({'feedback_logs': feedback_logs})

@app.route('/ask', methods=['POST'])
def ask():
    data = request.get_json()
    question = data.get('question', '').strip()
    user_id = data.get('user_id', 'web_user')
    
    if not question:
        return jsonify({'answer': 'ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.', 'is_fallback': True, 'success': False})
    
    # ê°€ë“œë ˆì¼ ê²€ì¦
    validation = guardrails.validate_question(question, user_id)
    if not validation['valid']:
        response = {
            'answer': validation['message'],
            'is_fallback': True,
            'success': False
        }
        if 'examples' in validation:
            response['examples'] = validation['examples']
        if validation.get('is_duplicate', False):
            response['is_duplicate'] = True
        
        save_chat_log(question, validation['message'], is_fallback=True)
        return jsonify(response)
    

    
    try:
        # RAG ì²´ì¸ ì‹¤í–‰
        answer = chain.invoke(question)
        save_chat_log(question, answer, is_fallback=False)
        return jsonify({'question': question, 'answer': answer, 'success': True})
    except Exception as e:
        print(f"Error: {e}")
        fallback_msg = guardrails.get_fallback_response('search_error')
        save_chat_log(question, fallback_msg, is_fallback=True)
        return jsonify({'answer': fallback_msg, 'is_fallback': True, 'success': False})

@app.route('/feedback', methods=['POST'])
def feedback():
    """í”¼ë“œë°± ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    data = request.get_json()
    question = data.get('question', '').strip()
    answer = data.get('answer', '').strip()
    feedback_type = data.get('feedback_type')
    is_cancel = data.get('is_cancel', False)
    user_id = data.get('user_id', 'web_user')
    
    if not question or not answer:
        return jsonify({'success': False, 'error': 'ì§ˆë¬¸ê³¼ ë‹µë³€ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    # í”¼ë“œë°± ì·¨ì†Œì¸ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
    if is_cancel:
        feedback_type = 'cancelled'
    
    # í”¼ë“œë°± ë¡œê·¸ ì €ì¥
    save_feedback_log(question, answer, feedback_type, user_id)
    
    return jsonify({'success': True, 'message': 'í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.'})

@app.route('/examples', methods=['GET'])
def get_examples():
    examples = guardrails.get_welcome_examples()
    return jsonify({'examples': examples})

# ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
vectorstore = None

def add_documents_to_vectorstore(new_documents):
    """ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ì— ìƒˆë¡œìš´ ë¬¸ì„œë“¤ì„ ì¶”ê°€"""
    global vectorstore
    
    if vectorstore is None:
        vectorstore = init_vectorstore()
    
    # í…ìŠ¤íŠ¸ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=120)
    split_documents = text_splitter.split_documents(new_documents)
    
    # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
    vectorstore.add_documents(split_documents)
    
    # ì €ì¥
    vectorstore.save_local(VECTOR_DIR)
    
    print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ì— {len(split_documents)}ê°œ ì²­í¬ ì¶”ê°€ ì™„ë£Œ")
    return True

def add_new_data_from_json(json_file_path):
    """ìƒˆ JSON íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€"""
    from langchain_core.documents import Document
    
    # JSON íŒŒì¼ ì½ê¸°
    with open(json_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ë¬¸ì„œ ìƒì„±
    docs = []
    for item in data:
        content = f"ì œëª©: {item['title']}\n\n"
        content += f"URL: {item['url']}\n\n" 
        content += f"ë‚´ìš©: {item['content']}\n\n"
        
        # ì²¨ë¶€íŒŒì¼ ë‚´ìš© ì¶”ê°€
        if 'attachments' in item and item['attachments']:
            for attachment in item['attachments']:
                content += f"ì²¨ë¶€íŒŒì¼: {attachment['file_name']}\n\n"
                content += f"íŒŒì¼ë‚´ìš©: {attachment['text']}\n\n"
                
        doc = Document(page_content=content, metadata={"source": item['title']})
        docs.append(doc)
    
    # ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
    add_documents_to_vectorstore(docs)
    print(f"ğŸ“„ {len(docs)}ê°œ ë¬¸ì„œë¥¼ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤")
    return True

def add_text_to_vectorstore(title, content, url="", metadata=None):
    """í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€"""
    from langchain_core.documents import Document
    
    doc_content = f"ì œëª©: {title}\n\n"
    if url:
        doc_content += f"URL: {url}\n\n"
    doc_content += f"ë‚´ìš©: {content}\n\n"
    
    if metadata is None:
        metadata = {"source": title}
    
    doc = Document(page_content=doc_content, metadata=metadata)
    add_documents_to_vectorstore([doc])
    print(f"ğŸ“„ ìƒˆ ë¬¸ì„œ '{title}' ì¶”ê°€ ì™„ë£Œ")
    return True

@app.route('/admin/add_data', methods=['POST'])
@admin_required  
def admin_add_data():
    """ê´€ë¦¬ìê°€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    try:
        data = request.get_json()
        
        if 'json_file' in data:
            # JSON íŒŒì¼ ê²½ë¡œë¡œ ì¶”ê°€
            json_file = data['json_file']
            current_dir = os.path.dirname(os.path.abspath(__file__))
            json_path = os.path.join(current_dir, json_file)
            
            if os.path.exists(json_path):
                add_new_data_from_json(json_path)
                return jsonify({'success': True, 'message': f'{json_file}ì˜ ë°ì´í„°ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤'})
            else:
                return jsonify({'success': False, 'error': f'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}'})
                
        elif 'title' in data and 'content' in data:
            # ì§ì ‘ í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
            title = data['title']
            content = data['content']
            url = data.get('url', '')
            
            add_text_to_vectorstore(title, content, url)
            return jsonify({'success': True, 'message': f'ìƒˆ ë¬¸ì„œ "{title}"ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤'})
        
        else:
            return jsonify({'success': False, 'error': 'ì˜¬ë°”ë¥¸ ë°ì´í„° í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤ (titleê³¼ content ë˜ëŠ” json_file í•„ìš”)'})
            
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/admin/rebuild_vectorstore', methods=['POST'])
@admin_required
def admin_rebuild_vectorstore():
    """ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì™„ì „íˆ ì¬êµ¬ì¶•"""
    try:
        global vectorstore
        
        # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ì‚­ì œ
        if os.path.exists(VECTOR_DIR):
            import shutil
            shutil.rmtree(VECTOR_DIR)
            print("ğŸ—‘ï¸ ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ì‚­ì œ")
        
        # ìƒˆë¡œ ìƒì„±
        vectorstore = init_vectorstore()
        
        # ì²´ì¸ë„ ìƒˆë¡œ ì´ˆê¸°í™”
        global chain
        chain = init_chain()
        
        return jsonify({'success': True, 'message': 'ë²¡í„°ìŠ¤í† ì–´ê°€ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤'})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)